{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c289520-a4d5-4019-b650-9188a2cbcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ee95c9-99ab-4b62-ba45-06c064c88148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ba2f39-3b15-487f-928e-ca448cef22ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (2.9.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da306a74-7707-481c-a4f0-70eb8ef8fccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nico/data-engineering-zoomcamp/2_docker_sql/ny_taxi_postgres_data/base\n"
     ]
    }
   ],
   "source": [
    "# checking directory\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "466412a6-cf55-4c55-860d-21cd2b4ee37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file has 476386 rows.\n",
      "The CSV file has 265 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206851/2272091924.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path)\n"
     ]
    }
   ],
   "source": [
    "#Read the CSV file checking the rows\n",
    "csv_file_path = '/home/nico/data-engineering-zoomcamp/2_docker_sql/green_tripdata_2019-10.csv.gz'\n",
    "csv_file_path1 = '/home/nico/data-engineering-zoomcamp/2_docker_sql/taxi_zone_lookup.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "\n",
    "# Get the number of rows in the CSV\n",
    "row_count = len(df)\n",
    "print(f'The CSV file has {row_count} rows.')\n",
    "\n",
    "row_count1 = len(df1)\n",
    "print(f'The CSV file has {row_count1} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e617d61-1530-4888-8bdd-be3ca47e710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID                   int64\n",
      "lpep_pickup_datetime      object\n",
      "lpep_dropoff_datetime     object\n",
      "store_and_fwd_flag        object\n",
      "RatecodeID                 int64\n",
      "PULocationID               int64\n",
      "DOLocationID               int64\n",
      "passenger_count            int64\n",
      "trip_distance            float64\n",
      "fare_amount              float64\n",
      "extra                    float64\n",
      "mta_tax                  float64\n",
      "tip_amount               float64\n",
      "tolls_amount             float64\n",
      "ehail_fee                float64\n",
      "improvement_surcharge    float64\n",
      "total_amount             float64\n",
      "payment_type               int64\n",
      "trip_type                  int64\n",
      "congestion_surcharge     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file_path, nrows=1000)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e769ac0-a601-4878-995b-462b785fb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/nico/data-engineering-zoomcamp/2_docker_sql/green_tripdata_2019-10.csv.gz', nrows=5)\n",
    "df1 = pd.read_csv('/home/nico/data-engineering-zoomcamp/2_docker_sql/taxi_zone_lookup.csv', nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc79eb0a-b60e-42fc-9226-cc70de4bd8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-01 00:26:02</td>\n",
       "      <td>2019-10-01 00:39:58</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>5.88</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-01 00:18:11</td>\n",
       "      <td>2019-10-01 00:22:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-01 00:09:31</td>\n",
       "      <td>2019-10-01 00:24:47</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>228</td>\n",
       "      <td>2</td>\n",
       "      <td>7.50</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>22.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-01 00:37:40</td>\n",
       "      <td>2019-10-01 00:41:49</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-01 00:08:13</td>\n",
       "      <td>2019-10-01 00:17:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "      <td>2.52</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2019-10-01 00:26:02   2019-10-01 00:39:58                  N   \n",
       "1         1  2019-10-01 00:18:11   2019-10-01 00:22:38                  N   \n",
       "2         1  2019-10-01 00:09:31   2019-10-01 00:24:47                  N   \n",
       "3         1  2019-10-01 00:37:40   2019-10-01 00:41:49                  N   \n",
       "4         2  2019-10-01 00:08:13   2019-10-01 00:17:56                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1           112           196                1           5.88   \n",
       "1           1            43           263                1           0.80   \n",
       "2           1           255           228                2           7.50   \n",
       "3           1           181           181                1           0.90   \n",
       "4           1            97           188                1           2.52   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         18.0   0.50      0.5        0.00             0        NaN   \n",
       "1          5.0   3.25      0.5        0.00             0        NaN   \n",
       "2         21.5   0.50      0.5        0.00             0        NaN   \n",
       "3          5.5   0.50      0.5        0.00             0        NaN   \n",
       "4         10.0   0.50      0.5        2.26             0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3         19.30             2          1   \n",
       "1                    0.3          9.05             2          1   \n",
       "2                    0.3         22.80             2          1   \n",
       "3                    0.3          6.80             2          1   \n",
       "4                    0.3         13.56             1          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fadce39-9c0f-4c2d-85fc-c2c8b754aecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19da0f6-ac08-4b22-aad2-bf79c84bcebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   VendorID               5 non-null      int64  \n",
      " 1   lpep_pickup_datetime   5 non-null      object \n",
      " 2   lpep_dropoff_datetime  5 non-null      object \n",
      " 3   store_and_fwd_flag     5 non-null      object \n",
      " 4   RatecodeID             5 non-null      int64  \n",
      " 5   PULocationID           5 non-null      int64  \n",
      " 6   DOLocationID           5 non-null      int64  \n",
      " 7   passenger_count        5 non-null      int64  \n",
      " 8   trip_distance          5 non-null      float64\n",
      " 9   fare_amount            5 non-null      float64\n",
      " 10  extra                  5 non-null      float64\n",
      " 11  mta_tax                5 non-null      float64\n",
      " 12  tip_amount             5 non-null      float64\n",
      " 13  tolls_amount           5 non-null      int64  \n",
      " 14  ehail_fee              0 non-null      float64\n",
      " 15  improvement_surcharge  5 non-null      float64\n",
      " 16  total_amount           5 non-null      float64\n",
      " 17  payment_type           5 non-null      int64  \n",
      " 18  trip_type              5 non-null      int64  \n",
      " 19  congestion_surcharge   5 non-null      int64  \n",
      "dtypes: float64(8), int64(9), object(3)\n",
      "memory usage: 928.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae49d95-3e41-410e-999e-57daf5c1c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing to datetime specific columns\n",
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c1f0c18-8d69-406d-ad7e-85bfaf2713e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               5 non-null      int64         \n",
      " 1   lpep_pickup_datetime   5 non-null      datetime64[ns]\n",
      " 2   lpep_dropoff_datetime  5 non-null      datetime64[ns]\n",
      " 3   store_and_fwd_flag     5 non-null      object        \n",
      " 4   RatecodeID             5 non-null      int64         \n",
      " 5   PULocationID           5 non-null      int64         \n",
      " 6   DOLocationID           5 non-null      int64         \n",
      " 7   passenger_count        5 non-null      int64         \n",
      " 8   trip_distance          5 non-null      float64       \n",
      " 9   fare_amount            5 non-null      float64       \n",
      " 10  extra                  5 non-null      float64       \n",
      " 11  mta_tax                5 non-null      float64       \n",
      " 12  tip_amount             5 non-null      float64       \n",
      " 13  tolls_amount           5 non-null      int64         \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  5 non-null      float64       \n",
      " 16  total_amount           5 non-null      float64       \n",
      " 17  payment_type           5 non-null      int64         \n",
      " 18  trip_type              5 non-null      int64         \n",
      " 19  congestion_surcharge   5 non-null      int64         \n",
      "dtypes: datetime64[ns](2), float64(8), int64(9), object(1)\n",
      "memory usage: 928.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51590448-d828-4bf0-a541-1c7daec8b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5a6f347-31a6-4e46-ab2e-90bc4bb75978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7f3a969c06a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99992bc-4fa6-45c6-9924-f33c37798f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE green_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount BIGINT, \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type BIGINT, \n",
      "\tcongestion_surcharge BIGINT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating DDL\n",
    "print(pd.io.sql.get_schema(df, name='green_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fba26357-35e0-44c9-b8e2-01d4df5c9698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE lookup_data (\n",
      "\t\"LocationID\" BIGINT, \n",
      "\t\"Borough\" TEXT, \n",
      "\t\"Zone\" TEXT, \n",
      "\tservice_zone TEXT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generating DDL\n",
    "print(pd.io.sql.get_schema(df1, name='lookup_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0622b47c-bd13-470a-9e6e-4a03e5d63e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tables in the DB\n",
    "df.head(n=0).to_sql(name='green_taxi_data' , con=engine, if_exists='replace')\n",
    "df1.head(n=0).to_sql(name='lookup_data' , con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80af68be-ddce-4017-94a1-c6d8549c8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e06f151e-9b4d-422e-8451-50c50864b9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10.986 seconds and 100000 rows\n",
      "Processed 11.734 seconds and 100000 rows\n",
      "Processed 10.768 seconds and 100000 rows\n",
      "Processed 11.025 seconds and 100000 rows\n",
      "Processed 6.910 seconds and 76386 rows\n",
      "All data processed correctly.\n"
     ]
    }
   ],
   "source": [
    "# data ingestion for table green_taxi_data , in chunksizes of 100000 and parsing col index 3 to str, because there were some issues on the raw data with \n",
    "\n",
    "total_processed_rows = 0\n",
    "df_iter = pd.read_csv('/home/nico/data-engineering-zoomcamp/2_docker_sql/green_tripdata_2019-10.csv.gz', chunksize=100000, dtype={3: str})\n",
    "while True:\n",
    "    try:\n",
    "        t_start = time()\n",
    "        df = next(df_iter)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.to_sql(name='green_taxi_data' , con=engine, if_exists='append')\n",
    "\n",
    "# Track the number of rows processed\n",
    "        total_processed_rows += len(df)\n",
    "        \n",
    "        t_end = time()\n",
    "        print('Processed %.3f seconds and %d rows' % (t_end - t_start, len(df)))\n",
    "        \n",
    "      \n",
    "    except StopIteration:\n",
    "        print(\"All data processed correctly.\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13363d27-34bc-4c50-a070-e76b92c36877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same story, but look_up dataset is smaller, so we can do it straight ahead without the iterator\n",
    "#df_iter1 = pd.read_csv('/home/nico/data-engineering-zoomcamp/2_docker_sql/taxi_zone_lookup.csv', chunksize=100000)\n",
    "#while True:\n",
    " #   try:\n",
    "  #      t_start = time()\n",
    "   #     df1 = next(df_iter1)\n",
    "    #    df1.to_sql(name='lookup_data' , con=engine, if_exists='append')\n",
    "     #   t_end = time()\n",
    "      #  print('another brick in the wall... it took %.3f seconds' % (t_end-t_start))\n",
    "    #except StopIteration:\n",
    "     #   print(\"All data processed correctly.\")\n",
    "      #  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22445f38-0253-4fa3-8655-84b3a34dda49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476386\n",
      "476386\n",
      "Row counts match! 476386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206851/1452683953.py:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path)\n"
     ]
    }
   ],
   "source": [
    "# Query to get row count from the database\n",
    "count_query = \"SELECT COUNT(*) FROM green_taxi_data\"\n",
    "count_result = pd.read_sql(count_query, con=engine)\n",
    "\n",
    "# Get the count of rows\n",
    "db_count = count_result.iloc[0, 0]\n",
    "df = pd.read_csv(csv_file_path)\n",
    "row_count = len(df)\n",
    "\n",
    "print(row_count)\n",
    "print(db_count)\n",
    "# Compare with the processed row count\n",
    "if db_count == row_count:\n",
    "    print(\"Row counts match!\", db_count)\n",
    "else:\n",
    "    print(\"Row counts do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a322d9-5981-4d44-a485-ecadb8544661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion completed... it took 0.021 seconds\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('/home/nico/data-engineering-zoomcamp/2_docker_sql/taxi_zone_lookup.csv')\n",
    "\n",
    "t_start = time()\n",
    "df1.to_sql(name='lookup_data', con=engine, if_exists='append')\n",
    "t_end = time()\n",
    "\n",
    "print('Data ingestion completed... it took %.3f seconds' % (t_end - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a2ed8a6-1658-475a-a0ed-cf086d207e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "265\n",
      "Row counts match! 265\n"
     ]
    }
   ],
   "source": [
    "# Query to get row count from the database\n",
    "count_query1 = \"SELECT COUNT(*) FROM lookup_data\"\n",
    "count_result1 = pd.read_sql(count_query1, con=engine)\n",
    "\n",
    "# Get the count of rows\n",
    "db_count1 = count_result1.iloc[0, 0]\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "row_count1 = len(df1)\n",
    "\n",
    "print(row_count1)\n",
    "print(db_count1)\n",
    "# Compare with the processed row count\n",
    "if db_count1 == row_count1:\n",
    "    print(\"Row counts match!\", db_count1)\n",
    "else:\n",
    "    print(\"Row counts do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72390092-7d2f-4aab-bbdc-bfa3ac5763f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing some data alanlysis \n",
    "# Question 3. Trip Segmentation Count\n",
    "# During the period of October 1st 2019 (inclusive) and November 1st 2019 (exclusive), how many trips, respectively, happened:\n",
    "\n",
    "# Up to 1 mile\n",
    "# In between 1 (exclusive) and 3 miles (inclusive),\n",
    "# In between 3 (exclusive) and 7 miles (inclusive),\n",
    "# In between 7 (exclusive) and 10 miles (inclusive),\n",
    "# Over 10 miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce410e22-51a1-4a89-8342-e7937e2c318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up to 1 mile: 104830\n",
      "1 to 3 miles: 198995\n",
      "3 to 7 miles: 109642\n",
      "7 to 10 miles: 27686\n",
      "Over 10 miles: 35201\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q3_a = \"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM green_taxi_data \n",
    "    WHERE DATE(lpep_pickup_datetime) >= '2019-10-01' \n",
    "      AND DATE(lpep_pickup_datetime) < '2019-11-01' \n",
    "      AND trip_distance  <= 1\n",
    "\"\"\"\n",
    "q3_b = \"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM green_taxi_data \n",
    "    WHERE DATE(lpep_pickup_datetime) >= '2019-10-01' \n",
    "      AND DATE(lpep_pickup_datetime) < '2019-11-01' \n",
    "      AND trip_distance > 1\n",
    "      AND trip_distance <= 3\n",
    "\"\"\"\n",
    "q3_c = \"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM green_taxi_data \n",
    "    WHERE DATE(lpep_pickup_datetime) >= '2019-10-01' \n",
    "      AND DATE(lpep_pickup_datetime) < '2019-11-01' \n",
    "      AND trip_distance > 3\n",
    "      AND trip_distance <= 7\n",
    "\"\"\"\n",
    "q3_d = \"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM green_taxi_data \n",
    "    WHERE DATE(lpep_pickup_datetime) >= '2019-10-01' \n",
    "      AND DATE(lpep_pickup_datetime) < '2019-11-01' \n",
    "      AND trip_distance > 7\n",
    "      AND trip_distance <= 10\n",
    "\"\"\"\n",
    "q3_e = \"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM green_taxi_data \n",
    "    WHERE DATE(lpep_pickup_datetime) >= '2019-10-01' \n",
    "      AND DATE(lpep_pickup_datetime) < '2019-11-01' \n",
    "      AND trip_distance > 10\n",
    "\"\"\"\n",
    "\n",
    "#running queries\n",
    "q3_a_result = pd.read_sql(q3_a, con=engine)\n",
    "q3_b_result = pd.read_sql(q3_b, con=engine)\n",
    "q3_c_result = pd.read_sql(q3_c, con=engine)\n",
    "q3_d_result = pd.read_sql(q3_d, con=engine)\n",
    "q3_e_result = pd.read_sql(q3_e, con=engine)\n",
    "\n",
    "#printing results\n",
    "print(\"Up to 1 mile:\", q3_a_result.iloc[0, 0])\n",
    "print(\"1 to 3 miles:\", q3_b_result.iloc[0, 0])\n",
    "print(\"3 to 7 miles:\", q3_c_result.iloc[0, 0])\n",
    "print(\"7 to 10 miles:\", q3_d_result.iloc[0, 0])\n",
    "print(\"Over 10 miles:\", q3_e_result.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855416c7-ba64-41c6-92e8-1f8f27d66a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is some sort of precision issue with the answers to Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "addc7f9d-6f36-4aea-9ff7-938989256790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-31\n"
     ]
    }
   ],
   "source": [
    "#Question 4. Longest trip for each day\n",
    "# Which was the pick up day with the longest trip distance? Use the pick up time for your calculations.\n",
    "\n",
    "# Tip: For every day, we only care about one single trip with the longest distance.\n",
    "q4 = \"\"\"SELECT \n",
    "        DATE(lpep_pickup_datetime) AS day, \n",
    "        MAX(trip_distance) AS max_trip_distance\n",
    "        FROM green_taxi_data\n",
    "        GROUP BY day\n",
    "        ORDER BY max_trip_distance DESC\n",
    "        LIMIT 1\"\"\"\n",
    "q4_result = pd.read_sql(q4, con=engine)\n",
    "print(q4_result.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ab8cb59-70fd-43b9-a085-d710d1c77660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "East Harlem North\n"
     ]
    }
   ],
   "source": [
    "#Question 5.\n",
    "\n",
    "q5 = \"\"\"SELECT \"Zone\", sum(t1.total_amount) as total_amount \n",
    "        FROM green_taxi_data as t1 \n",
    "        LEFT join lookup_data as t2 \n",
    "        ON t1.\"PULocationID\"=t2.\"LocationID\" \n",
    "        WHERE DATE(t1.lpep_pickup_datetime)='2019-10-18' \n",
    "        GROUP BY \"Zone\" \n",
    "        HAVING sum(t1.total_amount)>13000 \n",
    "        ORDER BY total_amount DESC \n",
    "        LIMIT 3;\"\"\"\n",
    "q5_result = pd.read_sql(q5, con=engine)\n",
    "print(q5_result.iloc[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59276a3f-b10c-4851-aa10-14a9ec7f732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root@localhost:ny_taxi> select \"Zone\", sum(t1.total_amount) as total_amount from green_taxi_data as t1 left join lookup_data as t2 on t1.\"PULocationID\"=t2.\"LocationID\" where date(t1.lpep_pickup_datetime)='2019-1\n",
    "# 0-18' GROUP BY \"Zone\" HAVING sum(t1.total_amount)>13000 ORDER BY total_amount desc limit 3;\n",
    "# +---------------------+--------------------+\n",
    "# | Zone                | total_amount       |\n",
    "# |---------------------+--------------------|\n",
    "# | East Harlem North   | 18686.680000000088 |\n",
    "# | East Harlem South   | 16797.260000000068 |\n",
    "# | Morningside Heights | 13029.790000000034 |\n",
    "# +---------------------+--------------------+\n",
    "#SELECT 3\n",
    "#Time: 0.047s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04216f-c274-4928-a0c4-0ad49d961a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6. Largest tip\n",
    "#For the passengers picked up in October 2019 in the zone named \"East Harlem North\" which was the drop off zone that had the largest tip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bea3314-8034-41b2-b713-b8f3b5723a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JFK Airport\n"
     ]
    }
   ],
   "source": [
    "q6 = \"\"\"SELECT \n",
    "        t2_d.\"Zone\" AS dropoff_zone,\n",
    "        MAX(t1.tip_amount) AS largest_tip\n",
    "        FROM green_taxi_data AS t1\n",
    "        LEFT JOIN lookup_data AS t2_p ON t1.\"PULocationID\" = t2_p.\"LocationID\"\n",
    "        LEFT JOIN lookup_data AS t2_d ON t1.\"DOLocationID\" = t2_d.\"LocationID\"\n",
    "        WHERE t2_p.\"Zone\" = 'East Harlem North' \n",
    "        AND EXTRACT(MONTH FROM t1.lpep_pickup_datetime) = 10\n",
    "        AND EXTRACT(YEAR FROM t1.lpep_pickup_datetime) = 2019\n",
    "        GROUP BY t2_d.\"Zone\"\n",
    "        ORDER BY largest_tip DESC\n",
    "        LIMIT 1;\"\"\"\n",
    "q6_result = pd.read_sql(q6, con=engine)\n",
    "print(q6_result.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a750e-69e0-4703-8d8e-ecf121a06b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
